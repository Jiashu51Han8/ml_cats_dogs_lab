{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression: cat or dog?\n",
    "In this lab you will teach computer to distinguish between images of cats and dogs using Logistic Regression. \n",
    "The input dataset consists of 10,000 images manually labeled as ''cats'' and ''dogs''. The original dataset was downloaded from kaggle. \n",
    "\n",
    "Download the entire [folder](https://drive.google.com/file/d/1V4pAtGy7VOJQlxM3g8gyDee8h5k7VTSF/view?usp=sharing)  with images and unzip it into your local directory containing input files for this course. Then set the path below to point to this directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_dir = \"/users/hanjiashu/desktop/Fall2020/ML2020Labs/data/cat_dog_data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Building the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Import all the required libraries. \n",
    "If you get an import error on `keras`, run one of the next 2 cells to install `keras` in the current Jupyter kernel, and then rerun the import cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.DS_Store', 'training_set', 'test_set']\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"/users/hanjiashu/desktop/Fall2020/ML2020Labs/data/cat_dog_data\"\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from warnings import simplefilter\n",
    "# ignore all future warnings\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "from PIL import Image\n",
    "from keras import preprocessing\n",
    "import os\n",
    "\n",
    "cwd = os.getcwd()\n",
    "os.chdir(cwd)\n",
    "print(os.listdir(data_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: failed with initial frozen solve. Retrying with flexible solve.\n",
      "Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: \\ ^C\n",
      "failed with initial frozen solve. Retrying with flexible solve.\n",
      "\n",
      "CondaError: KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Install a conda package (with all its dependencies) in the current Jupyter kernel\n",
    "# this will work if you have a clean installation of anaconda\n",
    "# import sys\n",
    "# !conda install --yes --prefix {sys.prefix} keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow==1.6.0 (from versions: 2.2.0rc3, 2.2.0rc4, 2.2.0, 2.3.0rc0, 2.3.0rc1, 2.3.0rc2, 2.3.0)\u001b[0m\n",
      "\u001b[31mERROR: No matching distribution found for tensorflow==1.6.0\u001b[0m\n",
      "Collecting keras==2.1.5\n",
      "  Downloading Keras-2.1.5-py2.py3-none-any.whl (334 kB)\n",
      "\u001b[K     |████████████████████████████████| 334 kB 1.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pyyaml in /Users/hanjiashu/opt/anaconda3/lib/python3.8/site-packages (from keras==2.1.5) (5.3.1)\n",
      "Requirement already satisfied: scipy>=0.14 in /Users/hanjiashu/opt/anaconda3/lib/python3.8/site-packages (from keras==2.1.5) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /Users/hanjiashu/opt/anaconda3/lib/python3.8/site-packages (from keras==2.1.5) (1.18.5)\n",
      "Requirement already satisfied: six>=1.9.0 in /Users/hanjiashu/opt/anaconda3/lib/python3.8/site-packages (from keras==2.1.5) (1.15.0)\n",
      "Installing collected packages: keras\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: Keras 2.4.3\n",
      "    Uninstalling Keras-2.4.3:\n",
      "      Successfully uninstalled Keras-2.4.3\n",
      "Successfully installed keras-2.1.5\n",
      "Requirement already up-to-date: tensorflow in /Users/hanjiashu/opt/anaconda3/lib/python3.8/site-packages (2.3.0)\n",
      "Requirement already satisfied, skipping upgrade: wheel>=0.26 in /Users/hanjiashu/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (0.34.2)\n",
      "Requirement already satisfied, skipping upgrade: scipy==1.4.1 in /Users/hanjiashu/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.4.1)\n",
      "Requirement already satisfied, skipping upgrade: h5py<2.11.0,>=2.10.0 in /Users/hanjiashu/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.8 in /Users/hanjiashu/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.9.2 in /Users/hanjiashu/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (3.13.0)\n",
      "Requirement already satisfied, skipping upgrade: tensorflow-estimator<2.4.0,>=2.3.0 in /Users/hanjiashu/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied, skipping upgrade: astunparse==1.6.3 in /Users/hanjiashu/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied, skipping upgrade: numpy<1.19.0,>=1.16.0 in /Users/hanjiashu/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.18.5)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.12.0 in /Users/hanjiashu/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /Users/hanjiashu/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.32.0)\n",
      "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /Users/hanjiashu/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: gast==0.3.3 in /Users/hanjiashu/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (0.3.3)\n",
      "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /Users/hanjiashu/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (0.10.0)\n",
      "Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /Users/hanjiashu/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied, skipping upgrade: keras-preprocessing<1.2,>=1.1.1 in /Users/hanjiashu/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /Users/hanjiashu/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.11.2)\n",
      "Requirement already satisfied, skipping upgrade: tensorboard<3,>=2.3.0 in /Users/hanjiashu/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in /Users/hanjiashu/opt/anaconda3/lib/python3.8/site-packages (from protobuf>=3.9.2->tensorflow) (49.2.0.post20200714)\n",
      "Requirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in /Users/hanjiashu/opt/anaconda3/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (2.24.0)\n",
      "Requirement already satisfied, skipping upgrade: google-auth<2,>=1.6.3 in /Users/hanjiashu/opt/anaconda3/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.21.1)\n",
      "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /Users/hanjiashu/opt/anaconda3/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.0.1)\n",
      "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /Users/hanjiashu/opt/anaconda3/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied, skipping upgrade: tensorboard-plugin-wit>=1.6.0 in /Users/hanjiashu/opt/anaconda3/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.7.0)\n",
      "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /Users/hanjiashu/opt/anaconda3/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (3.2.2)\n",
      "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /Users/hanjiashu/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /Users/hanjiashu/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2.10)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/hanjiashu/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (1.25.9)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /Users/hanjiashu/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2020.6.20)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /Users/hanjiashu/opt/anaconda3/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied, skipping upgrade: rsa<5,>=3.1.4; python_version >= \"3.5\" in /Users/hanjiashu/opt/anaconda3/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.6)\n",
      "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in /Users/hanjiashu/opt/anaconda3/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.1.1)\n",
      "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /Users/hanjiashu/opt/anaconda3/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (1.3.0)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1<0.5.0,>=0.4.6 in /Users/hanjiashu/opt/anaconda3/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /Users/hanjiashu/opt/anaconda3/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (3.1.0)\n",
      "Collecting keras\n",
      "  Using cached Keras-2.4.3-py2.py3-none-any.whl (36 kB)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.9.1 in /Users/hanjiashu/opt/anaconda3/lib/python3.8/site-packages (from keras) (1.18.5)\n",
      "Requirement already satisfied, skipping upgrade: pyyaml in /Users/hanjiashu/opt/anaconda3/lib/python3.8/site-packages (from keras) (5.3.1)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.14 in /Users/hanjiashu/opt/anaconda3/lib/python3.8/site-packages (from keras) (1.4.1)\n",
      "Requirement already satisfied, skipping upgrade: h5py in /Users/hanjiashu/opt/anaconda3/lib/python3.8/site-packages (from keras) (2.10.0)\n",
      "Requirement already satisfied, skipping upgrade: six in /Users/hanjiashu/opt/anaconda3/lib/python3.8/site-packages (from h5py->keras) (1.15.0)\n",
      "Installing collected packages: keras\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: Keras 2.1.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Uninstalling Keras-2.1.5:\n",
      "      Successfully uninstalled Keras-2.1.5\n",
      "Successfully installed keras-2.4.3\n",
      "installed\n"
     ]
    }
   ],
   "source": [
    "# Alternatively - install keras package and its dependencies using pip\n",
    "# import sys\n",
    "# !pip install --upgrade tensorflow\n",
    "# !pip install --upgrade keras\n",
    "# print(\"installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Load images\n",
    "First check if the path to the directory is correct:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.DS_Store', 'training_set', 'test_set']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "cwd = os.getcwd()\n",
    "os.chdir(cwd)\n",
    "print(os.listdir(data_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next create two lists and fill them with the paths to the corresponding images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 4000)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cats_files = []\n",
    "train_path_cats = data_dir +\"/training_set/cats/\"\n",
    "for path in os.listdir(train_path_cats):\n",
    "    if '.jpg' in path:\n",
    "        train_cats_files.append(os.path.join(train_path_cats, path))\n",
    "        \n",
    "train_dogs_files = []\n",
    "train_path_dogs = data_dir +\"/training_set/dogs/\"\n",
    "for path in os.listdir(train_path_dogs):\n",
    "    if '.jpg' in path:\n",
    "        train_dogs_files.append(os.path.join(train_path_dogs, path))\n",
    "        \n",
    "len(train_cats_files), len(train_dogs_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the paths to each image in the training set.\n",
    "We need to convert each image into a numpy array. For this we use the preprocessing module in the `keras` library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 200\n",
    "sample_dog_file = train_dogs_files[k]\n",
    "img = preprocessing.image.load_img(sample_dog_file, target_size=(32,32))\n",
    "img_array = preprocessing.image.img_to_array(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x646307dd8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(np.uint8(img_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_array.shape\n",
    "# print(img_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each image is represented as a $64*64$ matrix of pixels, and for each pixel we have values of Red, Green, and Blue (RGB). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Images to numpy arrays\n",
    "Now we create training sets for cats and for dogs and then concatenate 2 sets into a single `X_train` dataset of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 32, 32, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# image dimensions: using 32x32 pixels just for speed\n",
    "d = 32\n",
    "X_train_orig = np.zeros((8000, d, d, 3), dtype='float32')\n",
    "for i in range(4000):    \n",
    "    path = train_cats_files[i]\n",
    "    img = preprocessing.image.load_img(path, target_size=(d, d))\n",
    "    X_train_orig[i] = preprocessing.image.img_to_array(img)\n",
    "\n",
    "for i in range(4000,8000):    \n",
    "    path = train_dogs_files[i-4000]\n",
    "    img = preprocessing.image.load_img(path, target_size=(d, d))\n",
    "    X_train_orig[i] = preprocessing.image.img_to_array(img)    \n",
    "\n",
    "X_train_orig.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. Flatten 3D image arrays\n",
    "Our model requires each object to be a 1D vector of features -\n",
    "we need to flatten our 3D image arrays.\n",
    "\n",
    "After reshaping we will have,\n",
    "$d*d*3$ features as a single array for each picture in the training set (8000 pics),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[38. 28. 19. ... 51. 39. 25.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(8000, 3072)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train_orig.reshape(8000,-1)\n",
    "print(X_train[0])\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5. Create class labels\n",
    "Now we need to create the corresponding class label vectors. We will mark the cats as class 1, and the dogs as class 0 (not cats)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At position 3 should be a cat: 1.0\n",
      "At position 4002 should be a dog: 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(8000,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_orig = np.ones((4000,)) # 1 - 4000 are cat pictures so our label is 1\n",
    "Y_train_orig = np.concatenate((Y_train_orig, np.zeros((4000,)))) # 4000 - 8000 are dog pictures so our label is 0\n",
    "Y_train = Y_train_orig.reshape(-1)\n",
    "print(\"At position 3 should be a cat:\", Y_train[3])\n",
    "print(\"At position 4002 should be a dog:\", Y_train[4002])\n",
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6. Build the model\n",
    "We are using the `LogisticRegression` class from `sklearn` package.\n",
    "<ul>\n",
    "<li>The <code>random_state</code> parameter tells to shuffle the samples, so the classifier does not see all the cats first, and then the dogs. Specifying  the `random_state` value ensures that the algorithm starts from the same random seed and produces reproducible results.</li> \n",
    "<li>The <code>max_iter</code> parameter tells algorithm to stop even if it did not reach the thrreshold for convergence yet.</li>\n",
    "    <li>In the <code>solver</code> parameter you can specify the algorithm which you want to use.</li>\n",
    "</ul>\n",
    "\n",
    "You can read more about the parameters of  `LogisticRegression` model [here](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hanjiashu/opt/anaconda3/envs/tensorflow_env/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=15, random_state=32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "algorithms = ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'] # default='lbfgs'\n",
    "logreg = linear_model.LogisticRegression(solver=algorithms[1], random_state = 32, max_iter= 15)\n",
    "logreg.fit (X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The score of the logistic regression classifier is simply a percentage of correctly predicted data points. This measure is called the **accuracy** of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 0.658375 \n"
     ]
    }
   ],
   "source": [
    "acc_train = logreg.score(X_train, Y_train)\n",
    "print(\"train accuracy: {} \".format(acc_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Lab Task 1: Model evaluation  \\[60%\\]\n",
    "Obviously, we are much more interested to see how our model performs on the test data. To create a test set, repeat steps 1.2-1.5 for the test_set folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Load images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1000)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_cats_files = []\n",
    "test_path_cats = data_dir +\"/test_set/cats/\"\n",
    "for path in os.listdir(test_path_cats):\n",
    "    if '.jpg' in path:\n",
    "        test_cats_files.append(os.path.join(test_path_cats,path))\n",
    "\n",
    "test_dogs_files = []\n",
    "test_path_dogs = data_dir +\"/test_set/dogs/\"\n",
    "for path in os.listdir(test_path_dogs):\n",
    "    if '.jpg' in path:\n",
    "        test_dogs_files.append(os.path.join(test_path_dogs, path))\n",
    "\n",
    "len(test_cats_files), len(test_dogs_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Images to numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 32, 32, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_orig = np.zeros((2000, 32, 32, 3), dtype='float32')  \n",
    "for i in range(1000):    \n",
    "    path = test_cats_files[i]\n",
    "    img = preprocessing.image.load_img(path, target_size=(32, 32))\n",
    "    X_test_orig[i] = preprocessing.image.img_to_array(img)\n",
    "\n",
    "for i in range(1000,2000):    \n",
    "    path = test_dogs_files[i-1000]\n",
    "    img = preprocessing.image.load_img(path, target_size=(32, 32))\n",
    "    X_test_orig[i] = preprocessing.image.img_to_array(img)    \n",
    "\n",
    "X_test_orig.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Flatten 3D image arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9254902  0.8901961  0.65882355 ... 0.9647059  0.9019608  0.7019608 ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2000, 3072)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = X_test_orig.reshape(2000,-1)\n",
    "## normalize the X_test here\n",
    "X_test = X_test/255\n",
    "print(X_test[0])\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Create class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test_orig = np.ones((1000,))\n",
    "Y_test_orig = np.concatenate((Y_test_orig, np.zeros((1000,))))\n",
    "Y_test = Y_test_orig.reshape(-1)\n",
    "Y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5. Accuracy for the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy: 0.604 \n"
     ]
    }
   ],
   "source": [
    "acc_test = logreg.score(X_test, Y_test)\n",
    "print(\"test accuracy: {} \".format(acc_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6. Improve the model\n",
    "If the predictive power of the classifier is too low, try to improve the model. Below are some suggestions for improving it. Rerun the model after each modification and see if the accuracy of prediction is improved. \n",
    "\n",
    "Carefully record the results of your experiments in a separate markdown cell.\n",
    "\n",
    "<ol>\n",
    "    <li>Increase value of $d$ (image dimensions) to 64.</li>\n",
    "    <li>Normalize values in pixel arrays by dividing each value by 255 (max RGB value).</li>\n",
    "    <li>Use a different model-fitting algorithm.</li>\n",
    "    <li>Modify default parameters of <code>LogisticRegression</code> class.</li>\n",
    "    <li>$\\ldots$</li>\n",
    "</ol>\n",
    "\n",
    "You can stop once you have a good accuracy for the test set (no less than 0.60)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0. I was getting the error of not running enough times, So I changed the iteration from 1000 to 5000. But it's still giving me errors.\n",
    "1. I then changed the max iteration from 1000 to 7000 so as to not cause any errors. but after changing this, I got a really bad score of 0.56.\n",
    "2. At this point I used about 3 hours on just running code. but I still have the error. So I chaged the iteration number from 7000 to 10000.\n",
    "3. I tried many things, I used d = 64, but this gave me a worse conclusion. before I got 0.57, and when I used d = 64, I got 0.53 for some reason.\n",
    "4. Then I normalized the pixel value by dividing 255, from 0.57, I got 0.584.\n",
    "5. then I tried using algorithm[3], which uses the algorithm saga, this gave me a better result of 0.595.\n",
    "6. But in the end, after running codes for 6 hours, I did not get a result that was above 0.6 that did not show me the warning of running too little time.\n",
    "7. in all these runs, the best result I got was actually iterations = 15, which gave me a test accuracy of 0.604."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7. Predict random cats\n",
    "Find a random image of a cat and another of a dog, and test your model to predict it. Follow all the steps to convert two images into an array of features and then call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " X_new = [[...], [...]]\n",
    "\n",
    "#load the data\n",
    "new_image_files = []\n",
    "new_path = \"/users/hanjiashu/desktop/Fall2020/ML2020Labs/ml_cats_dogs_lab/pic\"\n",
    "for path in os.listdir(new_path):\n",
    "    if '.jpg' in path:\n",
    "        new_image_files.append(os.path.join(new_path, path))\n",
    "print(new_image_files)\n",
    "\n",
    "# image to arrays\n",
    "X_new_orig = np.zeros((2, d, d, 3), dtype='float32')  \n",
    "for i in range(2):    \n",
    "    path = new_image_files[i]\n",
    "    img = preprocessing.image.load_img(path, target_size=(d, d))\n",
    "    X_new_orig[i] = preprocessing.image.img_to_array(img)\n",
    "\n",
    "# unroll the arrays\n",
    "X_new = X_new_orig.reshape(2,-1)\n",
    "## normalize the X_test here\n",
    "X_new = X_new/255\n",
    "model = logreg\n",
    "Y_new = model.predict(X_new)\n",
    "print(Y_new)\n",
    "\n",
    "#the cat and dog are both predicted as dogs..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submit your images with your lab, and specify which prediction did you obtain for each image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.8. Save model to file\n",
    "When you are happy with the performance of your model and want to use it to identify cats in the future, save it to file using pickle. An example how to save the model and then reload it can be found [here](\n",
    "https://machinelearningmastery.com/save-load-machine-learning-models-python-scikit-learn/).\n",
    "\n",
    "Test that you can save the model and then load it in the cell below. Put your saved model to your google drive folder and provide the link to it in your notebook submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.604\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pickle\n",
    "\n",
    "filename = 'catsdogs.sav'\n",
    "pickle.dump(logreg, open(filename, 'wb'))\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "result = loaded_model.score(X_test, Y_test)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Lab Task 2: Support Vector Machines \\[40%\\]\n",
    "First, watch the [video](https://www.youtube.com/watch?v=efR1C6CvhmE&vl=en) about another classifier: Support Vector Machine (SVM).\n",
    "\n",
    "Next, perform the cat/dog image classification learning using SVM.\n",
    "Learn about the parameters of the sklearn SVC class [here](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC # \"Support vector classifier\"\n",
    "svm = SVC(kernel='poly', C=1E3)\n",
    "svm.fit(X_train, Y_train)\n",
    "acc_test_svm = svm.score(X_test,Y_test)\n",
    "print(\"test accuracy: {} \".format(acc_test_svm))\n",
    "Y_new_svn = svn.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The accuracy I got was 0.67, which is pretty good already I think.\n",
    "I tried the kernel=\"poly\", but it gave me a worse answer, So I will not consider it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "SVM is a more powerful classifier than logistic regression. Try to achieve a better accuracy by playing with the algorithm parameters. Report the final values in a new markdown cell below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, in a newly added markdown cell briefly explain how do you understand the difference between the logistic regression and SVM learning algorithms. Pay a special attention to how these algorithms treat a decision boundary. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Difference:\n",
    "in my opinion, the SVM is tryinf to find the best margin, distance between the line and support vectors. that separates the 1 and 0. this is trying to reduce the error in the data.\n",
    "the logistic is trying to find the boudary that is near the optimal point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright &copy; 2020 Marina Barsky. All rights reserved."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
